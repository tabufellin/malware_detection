{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2a67c6e9-36d0-44e2-99a3-5b3cbea0a34c",
   "metadata": {},
   "source": [
    "Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38ff08d3-0146-4722-a9c3-e014156bb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras) (1.25.2)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Downloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting dm-tree (from keras)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.9 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-macosx_11_0_arm64.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, dm-tree, ml-dtypes, mdurl, h5py, absl-py, markdown-it-py, rich, keras\n",
      "Successfully installed absl-py-2.1.0 dm-tree-0.1.8 h5py-3.10.0 keras-3.0.5 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 rich-13.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd3b555c-7b65-4977-8407-3561893ea0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-macos==2.15.0 (from tensorflow)\n",
      "  Downloading tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.6-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.10.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.25.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.9.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.40.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading google_auth-2.28.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl (208.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.8/208.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.6-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_12_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.14.1-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Downloading google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.0.5\n",
      "    Uninstalling keras-3.0.5:\n",
      "      Successfully uninstalled keras-3.0.5\n",
      "Successfully installed astunparse-1.6.3 cachetools-5.3.3 flatbuffers-24.3.6 gast-0.5.4 google-auth-2.28.1 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.62.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 tensorflow-macos-2.15.0 termcolor-2.4.0 werkzeug-3.0.1 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbe4b99-490c-469e-bbeb-fb9eaa4740f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from functions_url import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27758ff-461b-45c9-898d-601c850abffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b039a2-1ad9-40e1-88fd-f5c2a4afe2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"MalBehavD-V1-dataset.csv\", sep = \",\")\n",
    "# Separator\n",
    "separator = ','\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "\n",
    "# Read the file line by line\n",
    "with open(\"MalBehavD-V1-dataset.csv\", 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        # Split the line using the separator\n",
    "        parts = line.strip().split(separator, 2)\n",
    "        # Append the parts to the data list\n",
    "        data.append(parts)\n",
    "\n",
    "# Construct DataFrame\n",
    "df = pd.DataFrame(data, columns=['sha256', 'labels', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f47532-612f-42f0-870f-bfacced1f772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c18291c481a192ed5003084dab2d8a117fd3736359218...</td>\n",
       "      <td>0</td>\n",
       "      <td>LdrUnloadDll,CoUninitialize,NtQueryKey,NtDupli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4683faf3da550ffb594cf5513c4cbb34f64df85f27fd1c...</td>\n",
       "      <td>0</td>\n",
       "      <td>NtOpenMutant,GetForegroundWindow,NtQueryKey,Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9a0aea1c7290031d7c3429d0e921f107282cc6eab854ee...</td>\n",
       "      <td>0</td>\n",
       "      <td>GetForegroundWindow,DrawTextExW,GetSystemInfo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e0f3e4d5f50afd9c31e51dd9941c5a52d57c7c524f5d11...</td>\n",
       "      <td>0</td>\n",
       "      <td>NtQueryValueKey,LdrUnloadDll,GlobalMemoryStatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ec2b6d29992f13e74015ff0b129150b4afae15c593e4b7...</td>\n",
       "      <td>0</td>\n",
       "      <td>LdrUnloadDll,GetSystemTimeAsFileTime,NtOpenKey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9cc731c2a95ea1d5b96396c1a0caf976e2965ee8a54b8e...</td>\n",
       "      <td>0</td>\n",
       "      <td>NtDuplicateObject,RegCloseKey,LdrUnloadDll,NtS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c8b2364e5f1b4b860cf20509ced195f86c59d41181c8ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>LdrGetProcedureAddress,SetUnhandledExceptionFi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46822662959c5efe393697dc73ae6a852aae9147751acd...</td>\n",
       "      <td>0</td>\n",
       "      <td>NtQueryValueKey,CoInitializeEx,CoUninitialize,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>282eb13c914a0a9865606221f51518208d50abac01801d...</td>\n",
       "      <td>0</td>\n",
       "      <td>NtDuplicateObject,DeviceIoControl,GetVolumePat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5a9a5ae741322bfea383c1384d616e466c435a24c44e33...</td>\n",
       "      <td>0</td>\n",
       "      <td>CreateToolhelp32Snapshot,LdrUnloadDll,NtOpenSe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sha256 labels  \\\n",
       "0  5c18291c481a192ed5003084dab2d8a117fd3736359218...      0   \n",
       "1  4683faf3da550ffb594cf5513c4cbb34f64df85f27fd1c...      0   \n",
       "2  9a0aea1c7290031d7c3429d0e921f107282cc6eab854ee...      0   \n",
       "3  e0f3e4d5f50afd9c31e51dd9941c5a52d57c7c524f5d11...      0   \n",
       "4  ec2b6d29992f13e74015ff0b129150b4afae15c593e4b7...      0   \n",
       "5  9cc731c2a95ea1d5b96396c1a0caf976e2965ee8a54b8e...      0   \n",
       "6  c8b2364e5f1b4b860cf20509ced195f86c59d41181c8ab...      0   \n",
       "7  46822662959c5efe393697dc73ae6a852aae9147751acd...      0   \n",
       "8  282eb13c914a0a9865606221f51518208d50abac01801d...      0   \n",
       "9  5a9a5ae741322bfea383c1384d616e466c435a24c44e33...      0   \n",
       "\n",
       "                                                text  \n",
       "0  LdrUnloadDll,CoUninitialize,NtQueryKey,NtDupli...  \n",
       "1  NtOpenMutant,GetForegroundWindow,NtQueryKey,Dr...  \n",
       "2  GetForegroundWindow,DrawTextExW,GetSystemInfo,...  \n",
       "3  NtQueryValueKey,LdrUnloadDll,GlobalMemoryStatu...  \n",
       "4  LdrUnloadDll,GetSystemTimeAsFileTime,NtOpenKey...  \n",
       "5  NtDuplicateObject,RegCloseKey,LdrUnloadDll,NtS...  \n",
       "6  LdrGetProcedureAddress,SetUnhandledExceptionFi...  \n",
       "7  NtQueryValueKey,CoInitializeEx,CoUninitialize,...  \n",
       "8  NtDuplicateObject,DeviceIoControl,GetVolumePat...  \n",
       "9  CreateToolhelp32Snapshot,LdrUnloadDll,NtOpenSe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f080b7b-662f-49d9-af57-32eab31d06a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2570, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f23ae5-4d62-4704-ac6a-cf819248ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2570 entries, 0 to 2569\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   sha256  2570 non-null   object\n",
      " 1   labels  2570 non-null   object\n",
      " 2   text    2570 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 60.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524efb4d-5e19-4a29-a471-bfc6c43088de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sha256\n",
       "ba2326683b333a123444d3210e563f4d21c5cd3541f2a7180256005bc5536a0a    3\n",
       "0a0b8cee43caf70f28f215261bb6075a0586967c9c930f7cfcd5388e4e49c891    2\n",
       "f6c4f53029d65a27d8e023257d8d1fc872d35d84e56c5e183d30039fb6ceb841    2\n",
       "edf1ffcebcd221b6d51a3f58fbebbe07da4fb44e82ce6d74347537818739a92c    2\n",
       "edf9f7fe9ecd32bc9f1486c356998dcc0382a48acf76034b0ea9da33404488db    2\n",
       "                                                                   ..\n",
       "7a5092b330c4acd5d2bd42276a972188004d0d85791ab937c47c3c400100f7eb    1\n",
       "b4f3cd7dd365ca2757997ccc9907835ae659eb90ced73c4be6b78a159a8e5ad3    1\n",
       "ed1443b6aa384a42138a2ec6a8911e61737f7ec45793dba8ff3a15e2b70a4fdc    1\n",
       "145944e86a8b4dd8fbb7b00cff52e12cba2e0a38938eb0dda58106d0d527d53b    1\n",
       "ed4d8f4196fd32dc08d8cda5e4c952c3ecf526e3491e9ec0c55067ed0ef11f37    1\n",
       "Name: count, Length: 2543, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sha256.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f03cee95-4c2a-4c40-a817-c8c6b0fd0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b947283-00e2-4a73-ac92-2a59beecbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2543, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates based on column 'sha256'\n",
    "#Even if it could be possible to the sha256 could be repeated I wanna remove it because I wanna drop that column and \n",
    "#I dont wanna have any type of garbage at the moment of analyzing the data.\n",
    "df_unique = df.drop_duplicates(subset=['sha256'])\n",
    "\n",
    "df_unique.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e76c1cfa-43c4-46be-9e0b-59ac1801a52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2543, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique = df_unique[df_unique['text'] != '']\n",
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd86a7-ee59-48cb-a31b-930adb731b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "663924f2-ef28-4989-b11a-bdf59c433399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_unique.drop('sha256', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7cd996b-98cc-465e-83dd-6be3b5d5e1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LdrUnloadDll,CoUninitialize,NtQueryKey,NtDupli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NtOpenMutant,GetForegroundWindow,NtQueryKey,Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GetForegroundWindow,DrawTextExW,GetSystemInfo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NtQueryValueKey,LdrUnloadDll,GlobalMemoryStatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LdrUnloadDll,GetSystemTimeAsFileTime,NtOpenKey...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               text\n",
       "0      0  LdrUnloadDll,CoUninitialize,NtQueryKey,NtDupli...\n",
       "1      0  NtOpenMutant,GetForegroundWindow,NtQueryKey,Dr...\n",
       "2      0  GetForegroundWindow,DrawTextExW,GetSystemInfo,...\n",
       "3      0  NtQueryValueKey,LdrUnloadDll,GlobalMemoryStatu...\n",
       "4      0  LdrUnloadDll,GetSystemTimeAsFileTime,NtOpenKey..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1f507-010d-4007-8a72-88a72fa3595c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a60798-caf8-4713-882c-2e677f516763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22a87a1a-9c96-4f79-b778-53e06d3306b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2950c44-b0c8-4af4-b5e7-4d599b8bc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_unique.text\n",
    "y = df_unique.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "451afe6b-2724-4517-8d71-847d14e92c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy promedio durante la validación cruzada: 0.9544943820224718\n",
      "Accuracy en el conjunto de prueba: 0.9646133682830931\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear un vectorizador de palabras\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorizar características para entrenamiento y prueba\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Crear un clasificador SVM\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Validación cruzada con K folds (K = 10)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(svm_classifier, X_train_vectorized, y_train, cv=kfold)\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de entrenamiento\n",
    "svm_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy_test = svm_classifier.score(X_test_vectorized, y_test)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Accuracy promedio durante la validación cruzada:\", np.mean(cv_scores))\n",
    "print(\"Accuracy en el conjunto de prueba:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca63cfb0-45b0-44e4-b8f1-e6630dca8958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "978a2f0d-b661-4059-83fd-750ecf77c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.str.split(',')\n",
    "type(X)\n",
    "X = X.apply(lambda x: ['\"{}\"'.format(elem) for elem in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "061f6e30-c810-48b6-bf23-63b044623cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [\"LdrUnloadDll\", \"CoUninitialize\", \"NtQueryKey...\n",
       "1       [\"NtOpenMutant\", \"GetForegroundWindow\", \"NtQue...\n",
       "2       [\"GetForegroundWindow\", \"DrawTextExW\", \"GetSys...\n",
       "3       [\"NtQueryValueKey\", \"LdrUnloadDll\", \"GlobalMem...\n",
       "4       [\"LdrUnloadDll\", \"GetSystemTimeAsFileTime\", \"N...\n",
       "                              ...                        \n",
       "2565    [\"CreateToolhelp32Snapshot\", \"GetCursorPos\", \"...\n",
       "2566    [\"NtDuplicateObject\", \"RegCloseKey\", \"LdrUnloa...\n",
       "2567    [\"GetCursorPos\", \"NtOpenSection\", \"CoUninitial...\n",
       "2568    [\"NtAllocateVirtualMemory\", \"LdrGetProcedureAd...\n",
       "2569    [\"LdrUnloadDll\", \"NtOpenSection\", \"CoUninitial...\n",
       "Name: text, Length: 2543, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f7f8bd5-b2cc-4dea-a7fd-2ec55f19167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [34, 277, 33, 80, 67, 279, 247, 127, 45, 82, 6...\n",
      "1       [100, 180, 33, 8, 160, 7, 4, 277, 60, 58, 124,...\n",
      "2       [180, 8, 279, 247, 127, 60, 58, 232, 124, 38, ...\n",
      "3       [60, 34, 286, 166, 29, 4, 120, 45, 219, 276, 2...\n",
      "4       [34, 54, 29, 39, 125, 120, 45, 219, 171, 276, ...\n",
      "                              ...                        \n",
      "2565    [204, 11, 277, 58, 34, 8, 160, 168, 127, 60, 1...\n",
      "2566    [80, 58, 34, 160, 7, 120, 60, 124, 74, 19, 163...\n",
      "2567    [11, 153, 277, 58, 34, 279, 7, 120, 60, 232, 1...\n",
      "2568    [219, 4, 125, 200, 54, 24, 276, 152, 60, 34, 2...\n",
      "2569    [34, 153, 277, 180, 1, 8, 7, 247, 127, 60, 82,...\n",
      "Name: text, Length: 2543, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a Pandas Series named 'data'\n",
    "data = X\n",
    "\n",
    "# Flatten the list of lists\n",
    "flat_list = [item for sublist in data for item in sublist]\n",
    "\n",
    "# Create a set to get unique elements\n",
    "unique_elements = set(flat_list)\n",
    "\n",
    "# Create a dictionary to map each unique element to a unique number\n",
    "element_to_number = {elem: i for i, elem in enumerate(unique_elements)}\n",
    "\n",
    "# Replace strings with numbers\n",
    "X = data.apply(lambda x: [element_to_number[elem] for elem in x])\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6935510a-c3fc-4d7c-b358-b1bf7efa3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e76bfea9-5004-4592-b52c-ff7d5e7e9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = X\n",
    "\n",
    "# Padding each sequence separately\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0eebe3fd-79df-4fb5-a1e3-a279d1bb3a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54,   4, 125, ..., 220, 220, 220],\n",
       "       [ 34, 153,  27, ..., 220, 220, 220],\n",
       "       [ 11,  14, 277, ..., 220, 220, 220],\n",
       "       ...,\n",
       "       [ 80, 153, 277, ..., 220, 220, 220],\n",
       "       [204,  80,  58, ..., 220, 220, 220],\n",
       "       [283,  34, 153, ..., 220, 220, 220]], dtype=int32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.3, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d27573ff-799c-4a53-a1cf-a7e1ff63e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del modelo\n",
    "vocab_size = 10000  # Tamaño del vocabulario\n",
    "embedding_dim = 100  # Dimensión de los embeddings\n",
    "num_filters = 128  # Número de filtros en la capa convolucional\n",
    "kernel_size = 5  # Tamaño del kernel en la capa convolucional\n",
    "dropout_rate = 0.5  # Tasa de dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8fe56e55-8049-4f5b-91a1-c0e6e7861aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el modelo CNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a5996f53-6194-4986-b625-48e2da076e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "023fd1a5-6c65-4a80-b09a-00f2472ed6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "845     0\n",
       "1437    1\n",
       "2434    1\n",
       "2428    1\n",
       "1205    0\n",
       "       ..\n",
       "1653    1\n",
       "1102    0\n",
       "1137    0\n",
       "1303    1\n",
       "867     0\n",
       "Name: labels, Length: 1780, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dfc28ff6-1891-4ab0-a9fc-68d0bdbea614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 54   4 125 ... 220 220 220]\n",
      " [ 34 153  27 ... 220 220 220]\n",
      " [ 11  14 277 ... 220 220 220]\n",
      " ...\n",
      " [ 80 153 277 ... 220 220 220]\n",
      " [204  80  58 ... 220 220 220]\n",
      " [283  34 153 ... 220 220 220]], shape=(1780, 175), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Convert each list in the Series to a NumPy array\n",
    "data_array = np.array(X_train.tolist())\n",
    "\n",
    "# Convert the NumPy array to a Tensor\n",
    "tensor_data = tf.constant(data_array)\n",
    "\n",
    "print(tensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0c813266-6726-4c42-bef7-eba295055420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_16\" is incompatible with the layer: expected shape=(None, 1000), found shape=(None, 175)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m      5\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/x9/syjg7y_n1rd2xhdx7vjpj2500000gn/T/__autograph_generated_file1mhex9g5.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_16\" is incompatible with the layer: expected shape=(None, 1000), found shape=(None, 175)\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(tensor_data, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5490a0a8-68a8-4d84-aac4-681d9c9cecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ... 220 220 220]\n",
      " [  0   0   0 ... 220 220 220]\n",
      " [  0   0   0 ... 220 220 220]\n",
      " ...\n",
      " [  0   0   0 ... 220 220 220]\n",
      " [  0   0   0 ... 220 220 220]\n",
      " [  0   0   0 ... 220 220 220]]\n",
      "845     [54, 4, 125, 89, 219, 120, 276, 74, 220, 220, ...\n",
      "1437    [34, 153, 27, 33, 59, 80, 67, 279, 88, 122, 10...\n",
      "2434    [11, 14, 277, 58, 1, 8, 258, 7, 259, 256, 66, ...\n",
      "2428    [1, 58, 80, 8, 279, 7, 98, 39, 247, 45, 74, 11...\n",
      "1205    [80, 153, 277, 58, 33, 34, 14, 120, 60, 124, 3...\n",
      "                              ...                        \n",
      "1653    [204, 80, 219, 196, 178, 275, 268, 100, 19, 25...\n",
      "1102    [34, 153, 277, 58, 33, 1, 8, 279, 174, 39, 247...\n",
      "1137    [80, 153, 277, 58, 33, 34, 8, 120, 174, 247, 1...\n",
      "1303    [204, 80, 58, 196, 1, 67, 259, 127, 60, 232, 1...\n",
      "867     [283, 34, 153, 277, 58, 33, 226, 1, 8, 279, 7,...\n",
      "Name: text, Length: 1780, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m     43\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Suponiendo que tienes tus datos de texto en X (una lista de listas de secuencias de enteros) y las etiquetas en y\n",
    "\n",
    "# Padding para que todas las secuencias tengan la misma longitud\n",
    "max_sequence_length = 1000  # Longitud máxima deseada de la secuencia\n",
    "X_padded = pad_sequences(X, maxlen=max_sequence_length)\n",
    "\n",
    "print (X_padded)\n",
    "# División de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train)\n",
    "# Parámetros del modelo\n",
    "vocab_size = 10000  # Tamaño del vocabulario\n",
    "embedding_dim = 100  # Dimensión de los embeddings\n",
    "num_filters = 128  # Número de filtros en la capa convolucional\n",
    "kernel_size = 5  # Tamaño del kernel en la capa convolucional\n",
    "dropout_rate = 0.5  # Tasa de dropout\n",
    "\n",
    "# Construir el modelo CNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84d2e8ea-4e55-4cb9-9a59-85f4ef8a52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51efdae3-ef0f-4f6d-a4dc-a14f905cbba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 10:37:54.438213: W tensorflow/core/framework/op_kernel.cc:1816] OP_REQUIRES failed at cast_op.cc:122 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node binary_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/var/folders/x9/syjg7y_n1rd2xhdx7vjpj2500000gn/T/ipykernel_42684/732320388.py\", line 21, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 2521, in binary_crossentropy\n\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_2635]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m##loss, accuracy = model.evaluate(X_test_padded, y_test)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m##print(\"Loss:\", loss)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m##print(\"Accuracy:\", accuracy)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node binary_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/var/folders/x9/syjg7y_n1rd2xhdx7vjpj2500000gn/T/ipykernel_42684/732320388.py\", line 21, in <module>\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/losses.py\", line 2521, in binary_crossentropy\n\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_2635]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suponiendo que tienes tus datos en X (texto combinado de los archivos) y y (etiquetas de maliciosidad)\n",
    "\n",
    "# Preprocesamiento de texto: tokenización y padding\n",
    "#max_sequence_length = 1000  # Longitud máxima de la secuencia de texto\n",
    "#vocab_size = 10000  # Tamaño del vocabulario\n",
    "#X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "#X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "# Construir el modelo CNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "\n",
    "model.fit(X_train_padded, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "\n",
    "##loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "##print(\"Loss:\", loss)\n",
    "##print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917a44a-b454-450c-ae1f-6490d47c935a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
